
\section{Introduction}

Interest in backbone was oriented from the study of phase transition in propositional formula.
Experiments have shown that there is an easy-hard-easy pattern for SAT problem as increasing of the ratio of clauses number to variables.

Given a propositional formula $\Phi$, an assignment $\lambda$ is a map from literals appeared in $\Phi$ to boolean variables $\{0,1\}$. In an assignment, a literal can only be assigned as TRUE(1) or FALSE(0).
Backbone of a formula $\Phi$ are a set of literals that assigned to TRUE in all models $\Phi$\cite{BCJ2001,KPJ2005,MJML2010}.

Backbone have been studied in random 3-SAT problems \cite{DOG2001}, model counting problem \cite{IMM2016}, optimization problems\cite{CJG2001,KPS2005,WTS2001}, as well as Maximal Satisfiability(MSS) problems\cite{MM2005}.

The identification of backbone finds many practical applications. For example, backbone improves the performance of WalkSAT \cite{SBK1993} by making biased moves in a local search \cite{ZWR2003}. WalkSAT is a random SAT solver using sampling and belief prorogation \cite{MAR2007} to search for models. Similarly, backbone information significantly contributes to the Lin-Kernighan(LK) local search algorithms when dealing with Travel Salesman Problem \cite{ZWL2005}.

A more recent application of backbones arises in \cite{Z11}. A number of backbones extracting approaches are proposed and applied to post silicon fault localisation. The results show that backbones extracting using SAT solvers are suitable for large scale applications with only a little SAT solver calls.

As shown above, finding backbone is the key in many practical applications, such as planning problem and constraint satisfaction problem. It has been proved that backbone computing is a co-NP problem\cite{Jan10}, which have rise huge challenges.

%% Different approaches have been proposed over the years for computing backbone. Earlier work proposed modification to na\"{\i}ve model enumeration algorithm by scale down the initial estimation of backbone literals \cite{Z11}. It demonstrate the unity of backbones in post-silicon validation with case studies. However, compared to SAT problem, this work was not efficiency enough when dealing with large formula from practical applications. Another approach employs the unsatisfiable reason provided by SAT solver, whenever the reason contains only one literal, it implies that the literal is a backbone literal. According to the author, for formula with lower percentages of backbone, it performs significantly better. When the backbone percentage of formulae are over 25\%, it behave very similarly to the approach that check whether a literal is a backbone literal one literal by one literal \cite{MJML2010}.

In this paper, we developed a novel approach \tool for improving recent backbone computation algorithms inspired by the work of \cite{Z11} and \cite{JLM15}. We leverage Greedy and Whitening Algorithm together, computes backbone of a propositional formula in three steps: computing an under-approximation of non-backbone, computing an approximation of backbone, computing accurate backbone. Experiments are conducted to evaluate \tool, results showed that \tool is compatible with cb100 which is the state-of-art. Less total computing time is needed for \tool compared with cb100.

%% This new approach first computes a base under-approximation $\NBLap$ of backbone literals of a given formula. Given a model $\lambda$ of a formula $\Phi$, the assignment $\lambda[\neg l]$ is a model if for every clause $\phi\in\Phi_l$ that has $l$, $\lambda[\neg l]\models\phi$, i.e., $\lambda[\neg l]\models\Phi_l$. It implies that if a literal $l$ is not an essential(unique satisfy literal) in any clause to the given $\lambda$, then $l\in\NBL(\Phi)$. We apply a Greedy-based algorithm to generate more models without calling a SAT solver and add more non-backbone literals into the base under-approximation, which results in the under-approximation of non-backbone literals $\NBLap$.
%%  Next, we apply a Whitening-based algorithm to compute the approximation $\BLap$. Whitening Algorithm returns a set of literals $F(\Phi, \lambda)$ which are probably backbone literals. We remove some of the non-backbone literals from $F(\Phi, \lambda)$ and resulted in $\BLap$ with a lower false positive.

This paper is organized as follows.
Section 2 introduces the concept used throughout the paper.
Section 3 presented a brief overview of out new approach \tool.
Section 4 and Section 5 presents the computation of an under-approximation of non-backbone and an approximation of backbone.
Section 6 presented the empirical evaluation of \tool compared to cb100 in the respect of total SAT solving time and total SAT calls number.
Section 7 and Section 8 discussed related work for this problem and concludes the paper.
